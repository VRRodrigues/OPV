# -*- coding: utf-8 -*-
"""
@author: vicre

This code was made to generate the input files from the SMILES codes obtained from the csv containing the dataset.
It filters the SMILES codes and then it uses the 'rdkit' package to generate the 3D coordinates, which are later used
  for creating the input files for Gaussian and ORCA.
Semi-empirical methods are used here.
The code is paralelized so as to run faster.
A directory is generated (output_dir_all), containing the following elements:
  - A directory containing the Gaussian input files
  - A directory containing the ORCA input files
  - A directory containing the XYZ files
  - A csv file listing the failed attempts of converting a specific SMILES code into 3D coordinates ("failed_attempts.csv")
  - A csv file listing the SMILES codes processed and the respective indexes atributed to them, in the generation of the Gaussian, ORCA and XYZ files ("table_name.csv")

"""

import os
from concurrent.futures import ThreadPoolExecutor
from rdkit import Chem
from rdkit.Chem import AllChem

def process_smiles(smiles, index, output_dir_xyz, output_dir_gjf, output_dir_orca):
    try:
        # Generate 2D molecular graph from SMILES
        mol = Chem.MolFromSmiles(smiles)
        if mol is None:
            print(f"Invalid SMILES string at index {index}: {smiles}")
            return None, f"molecule_{index}\t{smiles}"

        # Add hydrogens to the molecule
        mol = Chem.AddHs(mol)

        # Generate 3D conformation
        AllChem.EmbedMolecule(mol, useRandomCoords=True)
        # Use Force Field for an initial geometry optimization
        AllChem.UFFOptimizeMolecule(mol) 

        # Extract XYZ coordinates
        conformer = mol.GetConformer()
        atom_coordinates = [(atom.GetSymbol(), conformer.GetAtomPosition(atom.GetIdx()).x, 
                             conformer.GetAtomPosition(atom.GetIdx()).y, 
                             conformer.GetAtomPosition(atom.GetIdx()).z)
                            for atom in mol.GetAtoms()]

        # Write XYZ file
        xyz_filename = f"molecule_{index+1}.xyz"
        with open(os.path.join(output_dir_xyz, xyz_filename), 'w') as f:
            f.write(f"{len(atom_coordinates)}\n")
            f.write(f"SMILES: {smiles}\n")
            for atom, x, y, z in atom_coordinates:
                f.write(f"{atom} {x:.6f} {y:.6f} {z:.6f}\n")

        #print(f"Molecule {index+1}, XYZ file saved as {xyz_filename}")

        # Prepare the Gaussian input file content
        net_charge = Chem.GetFormalCharge(mol)

        # Calculate the number of unpaired electrons
        unpaired_electrons = sum(atom.GetNumRadicalElectrons() for atom in mol.GetAtoms())
        spin_multiplicity = 2 * unpaired_electrons + 1

        # Check if Selenium (Se) or Telurium (Te) is present in the molecule
        # If not present, the method AM1 is used, otherwise, the method PM7 is selected
        method = 'AM1'
        if any((atom.GetSymbol() == 'Se' or atom.GetSymbol() == 'Te') for atom in mol.GetAtoms()):
            method = 'PM7'

        gjf_content = f"%nproc=16\n%mem=16GB\n\n# {method} opt freq\n\nFrequency optimization of molecule_{index+1}\n\n{net_charge} {spin_multiplicity}\n"
        for atom, x, y, z in atom_coordinates:
            gjf_content += f"{atom} {x:.6f} {y:.6f} {z:.6f}\n"
        gjf_content +="\n"

        # Write the Gaussian input file
        gjf_filename = f"molecule_{index+1}.gjf"
        with open(os.path.join(output_dir_gjf, gjf_filename), 'w') as f:
            f.write(gjf_content)

        #print(f"Molecule {index+1}, Gaussian input file {gjf_filename} written.")

        # Prepare the ORCA input file content
        # ORCA uses a similar structure but with different keywords
        orca_keywords = "! GFN2-xTB-A Opt Freq TightSCF"

        orca_content = f"{orca_keywords}\n\n%pal\n  nprocs 16\n  mem 16000\nend\n\n* xyz {net_charge} {spin_multiplicity}\n"
        for atom, x, y, z in atom_coordinates:
            orca_content += f"{atom} {x:.6f} {y:.6f} {z:.6f}\n"
        orca_content += "*\n"

        # Write the ORCA input file
        orca_filename = f"molecule_{index+1}.inp"
        with open(os.path.join(output_dir_orca, orca_filename), 'w') as f:
            f.write(orca_content)

        #print(f"Molecule {index+1}, ORCA input file {orca_filename} written.")
        
        return f"{smiles}\tmolecule_{index+1}", None

    except Exception as e:
        print(f"Error processing SMILES string at index {index}: {smiles}")
        print(str(e))
        return None, f"molecule_{index}\t{smiles}"

def smiles_to_input_files(smiles_list, 
                          output_dir_all, 
                          output_dir_xyz='xyz_files', 
                          output_dir_gjf='gaussian_inputs',
                          output_dir_orca='orca_inputs',
                          table_name="table_name.csv",
                          failed_name="failed_attempts.csv"):
    # Create output directories if they don't exist
    os.makedirs(output_dir_xyz, exist_ok=True)
    os.makedirs(output_dir_gjf, exist_ok=True)
    os.makedirs(output_dir_orca, exist_ok=True)
    os.makedirs(output_dir_all, exist_ok=True)  # For tables

    table_name_content = "SMILES\tmolecule_id"
    failed_attempts = ""

    # Parallel processing using ThreadPoolExecutor
    with ThreadPoolExecutor() as executor:
        futures = {
            executor.submit(
                process_smiles, 
                smiles, 
                i, 
                output_dir_xyz, 
                output_dir_gjf, 
                output_dir_orca
            ): i 
            for i, smiles in enumerate(smiles_list)
        }
        for future in futures:
            table_entry, failure_entry = future.result()
            if table_entry:
                table_name_content += "\n" + table_entry
            if failure_entry:
                failed_attempts += "\n" + failure_entry

    # Write the consultation table
    table_filename = table_name if table_name else "table_name.csv"
    with open(os.path.join(output_dir_all, table_filename), 'w') as f:
        f.write(table_name_content)
    
    # Write the failure table
    failed_filename = failed_name if failed_name else "failed_attempts.csv"
    with open(os.path.join(output_dir_all, failed_filename), 'w') as f:
        f.write(failed_attempts)

if __name__ == "__main__":

    # FA dataset SMILES codes
    df1 = pd.read_csv('FA_Polymer.txt', delimiter='\t', encoding='windows-1252')
    smiles_FA = list(set(list(df['SMILES'])))

    # NFA dataset SMILES codes
    df2 = pd.read_csv('NFA_Polymer.txt', delimiter='\t')
    smiles_NFA = list(set(df['n(SMILES)']).union(set(df['p(SMILES)'])))    

    # Define output directories
    # The "output_dir_all" is the directory containing the directories the contains the <<xyz files>>,
    #    the <<gaussian input files>> and the <<orca input files>>
    output_dir_all_FA = ''  # choose a directory
    output_dir_all_NFA = '' # choose a directory
    output_dir_xyz = os.path.join(output_dir_all, 'xyz_files')
    output_dir_gjf = os.path.join(output_dir_all, 'gaussian_inputs')
    output_dir_orca= os.path.join(output_dir_all, 'orca_inputs')
    
    # Process the SMILES and generate input files
    smiles_to_input_files(
        smiles_list=smiles_FA,
        output_dir_all=output_dir_all_FA,
        output_dir_xyz=output_dir_xyz,
        output_dir_gjf=output_dir_gjf,
        output_dir_orca=output_dir_orca,
        table_name="table_name_FA.csv",
        failed_name="failed_attempts_FA.csv")

    smiles_to_input_files(
        smiles_list=smiles_NFA,
        output_dir_all=output_dir_all_NFA,
        output_dir_xyz=output_dir_xyz,
        output_dir_gjf=output_dir_gjf,
        output_dir_orca=output_dir_orca,
        table_name="table_name_NFA.csv",
        failed_name="failed_attempts_NFA.csv")
    
